<!DOCTYPE html>
<html lang="en-us">
  <head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <!-- Enable responsiveness on mobile devices-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    <meta name="theme-color" content="#1DB2E9">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#1DB2E9">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-status-bar-style" content="#1DB2E9">
    <title>
      Gamut for Early Music on Microfilms (GEMM) &middot; DDMAL
    </title>
    <!-- CSS -->
    <link rel="stylesheet" href="../../../assets/css/main.css" />
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
    <link href="https://fonts.googleapis.com/css?family=Montserrat|Raleway:300,400,500" rel="stylesheet">
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../../../public/mcgill_crest.png">
    <link rel="shortcut icon" href="../../../public/mcgill_crest.png">
    <!-- RSS -->
    <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
  </head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <nav class="navbar navbar-light fixed-top navbar-expand-lg bg-white">
    <a class="navbar-brand" href="../../../">DDMAL</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto" id="nav-items">
        <li class="nav-item">
          <a class="nav-link" href="../../../">Home <span class="sr-only">(current)</span></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../../lab_members/">Lab Members</a>
        </li>
        <li class="dropdown">
          <a class="dropdown-toggle" role="button" data-toggle="dropdown" href="#">Activities<span class="caret"></span></a>
          <ul class="dropdown-menu" role="menu">
            <li><a href='../../../activities/media/' target='_top' >Media</a></li>
            <li><a href='../../../activities/posters/' target='_top' >Posters</a></li>
            <li><a href='../../../activities/presentations/' target='_top' >Presentations</a></li>
            <li><a href='../../../activities/publications/' target='_top' >Publications</a></li>
          </ul>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../../research/">Research</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../../software/">Software</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../../events/">Events</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../../resources/">Resources</a>
        </li>
      </ul>
    </div>
  </nav>
  <body id ="Site" class='layout-reverse theme-base-db sidebar-overlay'>
    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
      content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="container content">
        <div class="page container">
          <h1 style="text-align: left;" class="page-title">Gamut for Early Music on Microfilms (GEMM)</h1>
          <div style="margin-bottom: 25px"></div>
          <p><br /></p>
          <h2 id="introduction">Introduction</h2>
          <p>Unlike text databases, online content-searchable databases of music scores are extremely rare. The main reasons are the cost of digitisation, the inaccessibility of original music scores and manuscripts, and the lack of sophisticated music recognition software. The proposed research will attempt to circumvent these problems by investigating the feasibility of using existing microfilms for digitisation.</p>
          <p>Compared to original scores, microfilms constitute more accessible and economical sources for digitisation (there are over 7000 music scores in microfilm format in North America). Scanned images of music scores can be made content searchable through the use of optical music recognition (OMR) softwares. The OMR system to be used and developed here will be based on two of the most advanced existing OMR technologies, namely, Gamut (Fujinaga 1997) and Aruspix (Pugin 2006), both developed by researchers involved in this project.</p>
          <p>The objective of this study is to determine whether the quality of images scanned from microfilm, rather than from the original score, is sufficient for the subsequent OMR process. If the digital image derived from microfilm is found to be acceptable for OMR, there will be tremendous economic benefits. The cost of building digital libraries is incurred mainly in the digitisation process. The cost of digitisation from microfilm is far lower than that from paper. Using microfilms may also prove highly advantageous in data collection. Original music manuscripts are scattered throughout the world in various libraries, museums, and archives. The exorbitant cost of travelling to these locations can be avoided through the use of microfilm collections that already exist in many music libraries. Finally, when a local archive decides to digitise its own collection, using available microfilms will obviate the necessity of handling and thereby potentially damaging precious manuscripts.</p>
          <p>The project will concentrate on music from Medieval and Renaissance periods, because access to original sources from these periods is particularly difficult and the softwares must be trained to recognise notation systems that differ from the common music notation system in current use. If the quality of images scanned from microfilm is sufficient to obtain reasonable results using the OMR process, a large amount of music can be made searchable, creating an incredible resource for music scholars throughout the world.<br />
            <br />
          </p>
          <h2 id="microfilms-and-scanning">Microfilms and Scanning</h2>
          <p>The microfilms of Early Music are the raw material for this research. The starting point was to select samples of sources and digitize them using a microfilm scanner (Minolta MS6000) with grayscale option. Different notation styles with varying degrees of print quality have been considered. As a general policy, a ‘backwards’ procedure was adopted, starting with sources printed around 1600 and then moving by steps to earlier and earlier documents, including manuscripts. During this project, we will study the feasibility of using microfilm by comparing the image quality of direct scans and microfilm scans of the same music scores where they are available in both formats. A high-quality flatbed scanner (Epson 1640XL) will be used for the experiment. The principal metric is the recognition rate of the OMR process, although visual inspection of the image may be sufficient in some cases.</p>
          <p>[<a href="../../../research/omr/gemm/microfilms_and_scanning">more</a>]<br />
            <br />
          </p>
          <h2 id="preprocessing">Preprocessing</h2>
          <p>One part of the current research is devoted to development and evaluation of pre-processing solutions. Standard approaches to pre-processing of degraded documents are considered, as well as approaches more specific to music such as staff detection (Fujinaga 2005). A particular attention is given to binarisation because it appears to be a critical step in OMR of early documents. For our preprocessing experiments, we use a framework for the creation of structured document analysis applications by domain experts called <a href="http://ldp.library.jhu.edu/projects/gamera/">Gamera</a> (MacMillan, Droettboom, and Fujinaga. 2002). Gamera has been used in another OMR research project, the <a href="http://levysheetmusic.mse.jhu.edu/">Levy Sheet Music Project</a> at the <a href="http://jhu.edu/">Johns Hopkins University</a>
            (Choudhury et al. 2001). The framework is also being further developed within the current research project, as the new techniques that have been developed (such as binarization algorithms) are being integrated into it.
          </p>
          <p>[<a href="../../../research/omr/gemm/Preprocessing/">more</a>]<br />
            <br />
          </p>
          <h2 id="omr-experiments">OMR Experiments</h2>
          <p>For our OMR experiments, we use mainly <a href="http://www.aruspix.net/">Aruspix</a>, a software application designed to perform optical recognition of early typographic music prints. It uses an innovative technique in OMR based on Hidden Markov Models and was developed initially as part of a PhD thesis in Musicology presented by Laurent Pugin at <a href="http://www.unige.ch/">Geneva University</a> (Pugin 2006). Within the current project, Aruspix is used as a research tool. It it used to perform evaluations (such as pre-processing evaluations), but it is also being developed further. The new scores considered in the present research and the data generated (mainly the ground-truth) enable a better evaluation of Aruspix itself and, hopefully, future improvments.<br />
            <br />
          </p>
          <h2 id="academic-advisory-board">Academic Advisory Board</h2>
          <ul>
            <li><a href="http://www.mcgill.ca/music/about-us/bio/julie-e-cumming">Julie Cumming</a> • McGill University</li>
            <li><a href="http://www.kcl.ac.uk/artshums/depts/music/people/acad/dillon/index.aspx">Emma Dillon</a> • King’s College London</li>
            <li><a href="http://medieval.fas.harvard.edu/people/thomas-forrest-kelly">Thomas Forrest Kelly</a> • Harvard University</li>
            <li><a href="http://music.wustl.edu/people/pesce">Dolores Pesce</a> • Washington University in St. Louis</li>
            <li><a href="http://www.peabody.jhu.edu/conservatory/faculty/Musicology/weiss/">Susan Forscher Weiss</a> • Johns Hopkins University<br />
              <br />
            </li>
          </ul>
          <h2 id="researchers">Researchers</h2>
          <ul>
            <li>John Ashley Burgoyne • McGill University</li>
            <li>Remi Chiu • McGill University</li>
            <li><a href="http://www.music.mcgill.ca/~ich/">Ichiro Fujinaga</a> • McGill University</li>
            <li><a href="http://www.music.mcgill.ca/~cmckay/">Cory McKay</a> • McGill University</li>
            <li>Laurent Pugin • McGill University<br />
              <br />
            </li>
          </ul>
          <h2 id="grants">Grants</h2>
          <p>The project is funded by SSHRC Research Grants:</p>
          <ul>
            <li>‘Feasibility of Digitizing Early Music on Microfilms for the Creation of Large-scale Content-Searchable Databases’ (Standard Research Grant; August 2005; $145,838).</li>
            <li>‘Enhancing optical music recognition technology of Early Music prints and manuscripts for musicological applications’ (Image, Text, Sound and Technology Grant; December 2006; $49,943).</li>
          </ul>
        </div>
        <br>
        <br>
      </div>
    </div>
    <label for="sidebar-checkbox" class="sidebar-toggle"></label>
    <footer id="sticky">
      <div class="footer-img-wrap">
        <img class="mcgill-img-footer" src="../../../assets/schulich_logo.png" alt="">
        <img class="ddmal-img-footer" src="../../../assets/Ddmal_logo_transp-bg_no-border_1600w.png" alt="">
      </div>
    </footer>
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>
    <script src="../../../js/bootstrap.js"></script>
    <script type="text/javascript">
      $(document).ready(function () {
          var url = window.location;
          $('ul.navbar-nav a[href="'+ url +'"]').parent().addClass('active');
          $('ul.navbar-nav a').filter(function() {
               return this.href == url;
          }).parent().addClass('active');
      });
    </script>
  </body>
</html>